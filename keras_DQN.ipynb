{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_DQN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqh7cPs7whHf",
        "outputId": "12902ac3-e058-4df9-c6d3-96884cafc728"
      },
      "source": [
        "# 環境確認\r\n",
        "!cat /etc/issue\r\n",
        "!echo \"-----------\"\r\n",
        "# ファイルサイズ\r\n",
        "# !df -h \r\n",
        "# !echo \"-----------\"\r\n",
        "# Memory\r\n",
        "# !free -h\r\n",
        "# !echo \"-----------\"\r\n",
        "# CPU\r\n",
        "\r\n",
        "# !cat /proc/cpuinfo\r\n",
        "# !echo \"-----------\"\r\n",
        "# GPU情報(GPU mode: ONのとき)\r\n",
        "!cat /proc/driver/nvidia/gpus/0000:00:04.0/information\r\n",
        "!echo \"-----\" \r\n",
        "!nvcc -v\r\n",
        "!echo \"-----\"\r\n",
        "!nvidia-smi\r\n",
        "!echo \"-----\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ubuntu 18.04.5 LTS \\n \\l\n",
            "\n",
            "-----------\n",
            "Model: \t\t Tesla T4\n",
            "IRQ:   \t\t 11\n",
            "GPU UUID: \t GPU-53d6a56f-960f-9844-29d6-9a8df4035c77\n",
            "Video BIOS: \t 90.04.96.00.01\n",
            "Bus Type: \t PCI\n",
            "DMA Size: \t 47 bits\n",
            "DMA Mask: \t 0x7fffffffffff\n",
            "Bus Location: \t 0000:00:04.0\n",
            "Device Minor: \t 0\n",
            "Blacklisted:\t No\n",
            "-----\n",
            "nvcc fatal   : No input files specified; use option --help for more information\n",
            "-----\n",
            "Tue Mar  9 12:59:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mbs425igyIOR",
        "outputId": "0fca73a7-4851-4ccb-bfc3-3b6ae01d6505"
      },
      "source": [
        "# GPUアサインされてるかチェック\r\n",
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irPN_g1-u_uA"
      },
      "source": [
        "# Paper Runner Task\r\n",
        "\r\n",
        "- testing deep Q-learning model\r\n",
        "- from section11: https://www.udemy.com/course/ai-master/\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbLCOMY0oDh0",
        "outputId": "a0a690ca-f723-47f7-cea9-fb6180fad22f"
      },
      "source": [
        "print(tf.__version__)\r\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n",
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEO4VSCxSinq"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib import animation, rc\r\n",
        "\r\n",
        "from keras.layers import Dense, ReLU\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "\r\n",
        "optimizer = RMSprop()\r\n",
        "\r\n",
        "class Brain:\r\n",
        "    def __init__(self, n_state, n_mid, n_action, gamma=0.9, r=0.99):\r\n",
        "        self.eps = 1.0 # ε\r\n",
        "        self.gamma = gamma # 割引率\r\n",
        "        self.r = r # 減衰率\r\n",
        "\r\n",
        "        model = Sequential()\r\n",
        "        model.add(Dense(n_mid, input_shape=(n_state, )))\r\n",
        "        model.add(ReLU())\r\n",
        "        model.add(Dense(n_mid))\r\n",
        "        model.add(ReLU())\r\n",
        "        model.add(Dense(n_action))\r\n",
        "        model.compile(loss=\"mse\", optimizer=optimizer)\r\n",
        "        self.model = model\r\n",
        "\r\n",
        "    def train(self, states, next_states, action, reward, terminal):\r\n",
        "        q = self.model.predict(states)\r\n",
        "        next_q = self.model.predict(next_states)\r\n",
        "        t = np.copy(q)\r\n",
        "        if terminal: # エピソード終了時\r\n",
        "            t[:, action] = reward\r\n",
        "        else:\r\n",
        "            t[:, action] = reward + self.gamma * np.max(next_q, axis=1)\r\n",
        "        \r\n",
        "        self.model.train_on_batch(states, t)\r\n",
        "\r\n",
        "    def get_action(self, states):\r\n",
        "        q = self.model.predict(states)\r\n",
        "        if np.random.rand() < self.eps:\r\n",
        "            action = np.random.randint(q.shape[1], size=q.shape[0])\r\n",
        "        else:\r\n",
        "            action = np.argmax(q, axis=1)\r\n",
        "        if self.eps > 0.1:\r\n",
        "            self.eps += self.r\r\n",
        "        return action\r\n",
        "\r\n",
        "class Agent:\r\n",
        "    def __init__(self, v_x, v_y_sigma, v_jump, brain):\r\n",
        "        self.v_x = v_x\r\n",
        "        self.v_y_sigma = v_y_sigma\r\n",
        "        self.v_jump = v_jump\r\n",
        "        self.brain = brain\r\n",
        "        self.reset()\r\n",
        "\r\n",
        "    def reset(self): #初期配置\r\n",
        "        self.x = -1 \r\n",
        "        self.y = 0\r\n",
        "        self.v_y = self.v_y_sigma * np.random.randn()\r\n",
        "\r\n",
        "    def step(self, g):\r\n",
        "        states = np.array([[self.y, self.v_y]])\r\n",
        "        self.x += self.v_x\r\n",
        "        self.y += self.v_y\r\n",
        "\r\n",
        "        reward = 0 #報酬\r\n",
        "        terminal = False #終了判定\r\n",
        "\r\n",
        "        # 報酬の設定\r\n",
        "        if self.x > 1.0:\r\n",
        "            reward = 1\r\n",
        "            terminal = True\r\n",
        "        elif self.y < -1.0 or self.y > 1.0:\r\n",
        "            reward = -1\r\n",
        "            terminal = True\r\n",
        "        reward = np.array([reward])\r\n",
        "\r\n",
        "        # 行動の決定\r\n",
        "        action = self.brain.get_action(states)\r\n",
        "        if action[0] == 0:\r\n",
        "            self.v_y -= g #自由落下\r\n",
        "        else:\r\n",
        "            self.v_y = self.v_jump #ジャンプ\r\n",
        "        \r\n",
        "        next_states = np.array([[self.y, self.v_y]])\r\n",
        "        brain.train(states, next_states, action, reward, terminal)\r\n",
        "\r\n",
        "        # 終了判定したら初期配置にもどる\r\n",
        "        if terminal:\r\n",
        "            self.reset()\r\n",
        "    \r\n",
        "\r\n",
        "class Environment: \r\n",
        "    def __init__(self, agent, g):\r\n",
        "        self.agent = agent\r\n",
        "        self.g = g\r\n",
        "    def step(self):\r\n",
        "        self.agent.step(self.g)\r\n",
        "        return (self.agent.x, self.agent.y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l0HEIoPS39Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96375d03-ccda-4ff1-eaf6-30c3c91e718b"
      },
      "source": [
        "# 動画保存するためにGoogleDriveへマウント\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "def animate(environment, interval, frames):\r\n",
        "    fig, ax = plt.subplots()\r\n",
        "    plt.close()\r\n",
        "    ax.set_xlim(( -1, 1))\r\n",
        "    ax.set_ylim((-1, 1))\r\n",
        "    sc = ax.scatter([], []) #散布図で位置を描画\r\n",
        "\r\n",
        "    def plot(data):\r\n",
        "        x, y = environment.step()\r\n",
        "        sc.set_offsets(np.array([[x, y]]))\r\n",
        "        return (sc,)\r\n",
        "\r\n",
        "    return animation.FuncAnimation(fig, plot, interval=interval, frames=frames, blit=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_bTnRRuUgKx"
      },
      "source": [
        "# ケース：ランダム行動\r\n",
        "\r\n",
        "n_state = 2\r\n",
        "n_mid = 32\r\n",
        "n_action = 2\r\n",
        "brain = Brain(n_state, n_mid, n_action, r=1.0)  # εの減衰なし\r\n",
        "\r\n",
        "v_x = 0.05\r\n",
        "v_y_sigma = 0.1\r\n",
        "v_jump = 0.2\r\n",
        "agent = Agent(v_x, v_y_sigma, v_jump, brain)\r\n",
        "\r\n",
        "g = 0.2\r\n",
        "environment = Environment(agent, g)\r\n",
        "\r\n",
        "anim = animate(environment, 50, 1024)\r\n",
        "rc('animation', html='jshtml')\r\n",
        "\r\n",
        "anim.save('PaperRunner_Random.mp4', writer=\"ffmpeg\")\r\n",
        "\r\n",
        "#描画完了するまでそこそこかかるんでコーヒータイム\r\n",
        "# anim "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Qsl7GNatt4v"
      },
      "source": [
        "# ケース：Q学習あり\r\n",
        "\r\n",
        "n_state = 2\r\n",
        "n_mid = 32\r\n",
        "n_action = 2\r\n",
        "brain = Brain(n_state, n_mid, n_action, r=0.99)  # εの減衰あり\r\n",
        "\r\n",
        "v_x = 0.05\r\n",
        "v_y_sigma = 0.1\r\n",
        "v_jump = 0.2\r\n",
        "agent = Agent(v_x, v_y_sigma, v_jump, brain)\r\n",
        "\r\n",
        "g = 0.2\r\n",
        "environment = Environment(agent, g)\r\n",
        "\r\n",
        "anim = animate(environment, 50, 1024)\r\n",
        "rc('animation', html='jshtml')\r\n",
        "\r\n",
        "anim.save('PaperRunner_DQN.mp4', writer=\"ffmpeg\")\r\n",
        "\r\n",
        "#描画完了するまでそこそこかかるんでコーヒータイム\r\n",
        "# anim "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy7MZocSKdsx",
        "outputId": "36688751-a14b-40c0-844c-f200d3c22442"
      },
      "source": [
        "# Driveに動画コピー\r\n",
        "!pwd\r\n",
        "!cp PaperRunner_Random.mp4 ./drive/MyDrive/PrjFX/Colab/\r\n",
        "!cp PaperRunner_DQN.mp4 ./drive/MyDrive/PrjFX/Colab/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB5-WtkowYwO"
      },
      "source": [
        "# 安定した学習のためのテクニック\r\n",
        "# experience replay\r\n",
        "# fixed target q-network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxb-FQAuwszL"
      },
      "source": [
        "# ケース：SARSA\r\n",
        "# 参考: Q学習との違い https://qiita.com/triwave33/items/cae48e492769852aa9f1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}